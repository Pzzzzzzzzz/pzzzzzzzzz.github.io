---
title: "（改良）不同卷积核大小，步长以及是否补零的影响基于MNIST"
date: 2023-04-08T13:46:02+08:00
draft: false
---

深度学习：第二个实验

目的：学习不同的卷积核（3，3）、（5，5）、（7，7）

数据：手写体数据；

实验内容：

1. 利用手写体数据的分类，设计一个卷积神经网络；

2. 利用（3，3）、（5，5）、（7，7）三种不同的卷积核、步长1、2，比较补零和不补零的结果。（要求设计2-3卷积层）

3. 利用公式，写出每层的输入和输出维度，并讨论维度的不同对于运行精确度和速度的影响。


```python

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt


# 定义超参数
input_size = 28 * 28
num_classes = 10
num_epochs = 2
batch_size = 300
learning_rate = 0.001

# MNIST数据集
train_dataset = dsets.MNIST(root='./data', 
                            train=True, 
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data', 
                           train=False, 
                           transform=transforms.ToTensor())

# 数据加载器
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)


class ConvNet(nn.Module):
    def __init__(self, num_classes):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*32, num_classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
     

# 不同的卷积核大小和padding的组合
kernel_sizes = [(3,3), (5,5), (7,7)]
paddings = [(0,0), (1,1)]
strides = [1, 2]

# 定义记录loss和accuracy的列表
train_loss_history = []
train_acc_history = []
test_loss_history = []
test_acc_history = []

# 绘制损失图表
fig, ax = plt.subplots(nrows=len(kernel_sizes), ncols=len(paddings), figsize=(12, 10))

for r, kernel_size in enumerate(kernel_sizes):
    for c, padding in enumerate(paddings):
        ax[r, c].set_title(f"Kernel Size: {kernel_size}, Padding: {padding}")
        ax[r, c].set_xlabel("Epochs")
        ax[r, c].set_ylabel("Loss")
        for stride in strides:
            print(f"Kernel Size: {kernel_size}, Padding: {padding}, Stride: {stride}")
            # 定义模型
            model = ConvNet(num_classes)

            # 定义损失函数和优化器
            criterion = nn.CrossEntropyLoss()
            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

            # 训练和测试模型
            losses_train = []
            accuracies_train = []
            losses_test = []
            accuracies_test = []
            total_step = len(train_loader)
            for epoch in range(num_epochs):
                for i, (images, labels) in enumerate(train_loader):
                    # 向前传递
                    outputs = model(images)
                    loss = criterion(outputs, labels)

                    # 向后传播和优化
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    # 计算在训练集上的准确率和损失
                    total = labels.size(0)
                    _, predicted = torch.max(outputs.data, 1)
                    correct = (predicted == labels).sum().item()
                    train_acc = correct / total
                    train_loss = loss.item()
                    train_loss_history.append(train_loss)
                    train_acc_history.append(train_acc)

                    if (i + 1) % 100 == 0:
                        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'
                              .format(epoch + 1, num_epochs, i + 1, total_step, train_loss, train_acc * 100))

                # 在测试集上测试模型
                with torch.no_grad():
                    correct = 0
                    total = 0
                    test_loss = 0
                    for images, labels in test_loader:
                        outputs = model(images)
                        loss = criterion(outputs, labels)
                        test_loss += loss.item()
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()

                    test_acc = correct / total
                    test_loss_history.append(test_loss)
                    test_acc_history.append(test_acc)

                    print('Epoch [{}/{}], Testing Loss: {:.4f}, Testing Accuracy: {:.2f}%'
                          .format(epoch + 1, num_epochs, test_loss, test_acc * 100))

                # 记录loss和accuracy
                losses_train.append(train_loss)
                accuracies_train.append(train_acc)
                losses_test.append(test_loss)
                accuracies_test.append(test_acc)

            # 可视化loss和accuracy
            ax[r, c].plot(losses_train, label=f"Train,{stride}")
            ax[r, c].plot(losses_test, label=f"Test,{stride}")
            ax[r, c].legend()

fig.tight_layout()

# 绘制准确率图表
fig, ax = plt.subplots(nrows=len(kernel_sizes), ncols=len(paddings), figsize=(12, 10))

for r, kernel_size in enumerate(kernel_sizes):
    for c, padding in enumerate(paddings):
        ax[r, c].set_title(f"Kernel Size: {kernel_size}, Padding: {padding}")
        ax[r, c].set_xlabel("Epochs")
        ax[r, c].set_ylabel("Accuracy")
        for stride in strides:
            ax[r, c].plot(accuracies_train, label=f"Train,{stride}")
            ax[r, c].plot(accuracies_test, label=f"Test,{stride}")
            ax[r, c].legend()

fig.tight_layout()
plt.show()

```


![](https://pzzzzzzzzz.github.io/实验二images/LOSS.png)
![](https://pzzzzzzzzz.github.io/实验二images/ACCURARY.png)


第一层卷积层：
输入维度：28×28×1
过滤器数量：16
卷积核大小：3×3
padding大小：1
stride大小：1
输出维度：28×28×16
第一层池化层：
输入维度：28×28×16
池化大小：2×2
stride大小：2
输出维度：14×14×16
第二层卷积层：
输入维度：14×14×16
过滤器数量：32
卷积核大小：3×3
padding大小：1
stride大小：1
输出维度：14×14×32
第二层池化层：
输入维度：14×14×32
池化大小：2×2
stride大小：2
输出维度：7×7×32
全连接层：
输入维度：7×7×32
输出维度：10

总结：当网络的输入和中间层的维度变大时，模型需要处理更多的数据，计算量也会随之增加，导致运行速度变慢。但是，在每个网络层选择的卷积核尺寸、步长、padding 等不同参数的设置，也会对模型的速度和精确度产生影响。

例如，在卷积层中，卷积核和padding的设置都会影响输出的维度和计算速度。使用较大的卷积核和更多的卷积核在提取图像特征方面更有效，但是卷积核的增加也相应地增加了计算复杂度，会使模型训练和测试的时间变慢。相反，使用较小的卷积核和更少的卷积核可以在一定程度上减少计算量，提高运行速度，但是可能会失去某些图像特征的细节，影响建模精度。因此在实际应用中需要根据数据集的影响因素及识别的需求选择合理的卷积核大小。
