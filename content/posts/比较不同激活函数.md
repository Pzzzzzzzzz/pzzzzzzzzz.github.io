---
title: "测试各种激活函数"
date: 2023-03-31T13:46:02+08:00
draft: false
---

深度学习:第一个实验
利用MNIST数据集上进行激活函数的训练实验实验要求:
利用手写体数据的数据集，对不同的激活函数进行分析和比较 (SELU，ELU，Leaky-ReLU,ReLU等)
网络可以用最简单的前馈全连接网络(自行设)
要写出分析结果，并讨论可能的原因

```python

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.datasets as datasets
import torchvision.transforms as transforms

#定义神经网络
class Net(nn.Module):
    def __init__(self, activation):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 10)
        self.activation = activation

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.activation(self.fc1(x))
        x = self.activation(self.fc2(x))
        x = F.softmax(self.fc3(x), dim=1)
        return x
#定义激活函数
selu = nn.SELU()
elu = nn.ELU()
leaky_relu = nn.LeakyReLU()
relu = nn.ReLU()

#定义批量大小和迭代的数量
batch_size = 256
num_epochs = 10

#加载MNIST数据集
train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)

#创造loaders
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# 训练和测试不同的激活函数的神经网络
for activation in [selu, elu, leaky_relu, relu]:
    # Initialize the neural network
    net = Net(activation)

    # 定义了损失函数和优化器
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)

    #训练神经网络
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            # Forward pass
            outputs = net(images)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i+1) % 100 == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))

        #测试神经网络
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in test_loader:
                outputs = net(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        print('Accuracy of the network with {} activation function on the test images: {} %'.format(activation.__class__.__name__, 100 * correct / total))

**可以将Loss做成曲线按照不同集合进行对比**
```