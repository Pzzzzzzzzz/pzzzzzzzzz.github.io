---
title: "测试各种激活函数"
date: 2023-03-31T13:46:02+08:00
draft: false
---

深度学习:第一个实验
利用MNIST数据集上进行激活函数的训练实验实验要求:
利用手写体数据的数据集，对不同的激活函数进行分析和比较 (SELU，ELU，Leaky-ReLU,ReLU等)
网络可以用最简单的前馈全连接网络(自行设)
要写出分析结果，并讨论可能的原因

```python

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

#接着，我们需要加载MNIST数据集，并进行数据预处理：

train_dataset = datasets.MNIST(root='data/', train=True, transform=transforms.ToTensor(), download=True)
test_dataset = datasets.MNIST(root='data/', train=False, transform=transforms.ToTensor())

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)

#接下来，我们可以定义一个简单的前馈全连接神经网络，并选择不同的激活函数进行比较：

class Net(nn.Module):
    def __init__(self, activation):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
        if activation == 'relu':
            self.activation = nn.ReLU()
        elif activation == 'leaky_relu':
            self.activation = nn.LeakyReLU()
        elif activation == 'elu':
            self.activation = nn.ELU()
        elif activation == 'selu':
            self.activation = nn.SELU()

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)
        return x
    
#然后，我们可以定义训练函数和测试函数：

def train(net, dataloader, criterion, optimizer, device):
    net.train()
    running_loss = 0.0
    for i, (inputs, labels) in enumerate(dataloader, 0):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    return running_loss / len(dataloader)

def test(net, dataloader, criterion, device):
    net.eval()
    correct = 0
    total = 0
    running_loss = 0.0
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    acc = 100.0 * correct / total
    return running_loss / len(dataloader), acc

#最后，我们可以定义训练代码，并使用Matplotlib绘制训练曲线和测试曲线：

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
activations = ['relu', 'leaky_relu', 'elu', 'selu']
train_loss_list = []
test_loss_list = []
test_acc_list = []

for activation in activations:
    net = Net(activation).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.01)

    train_loss_epoch_list = []
    test_loss_epoch_list = []
    test_acc_epoch_list = []
    for epoch in range(10):
        train_loss = train(net, train_loader, criterion, optimizer, device)
        test_loss, test_acc = test(net, test_loader, criterion, device)
        train_loss_epoch_list.append(train_loss)
        test_loss_epoch_list.append(test_loss)
        test_acc_epoch_list.append(test_acc)
        print('{:d}, {:s}, Train Loss: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.2f}'.format(
              epoch+1, activation.upper(), train_loss, test_loss, test_acc))
    train_loss_list.append(train_loss_epoch_list)
    test_loss_list.append(test_loss_epoch_list)
    test_acc_list.append(test_acc_epoch_list)

fig1, axs1 = plt.subplots(2, 2, figsize=(12, 12))
fig2, axs2 = plt.subplots(2, 2, figsize=(12, 12))

for i, (activation, train_loss_epoch_list, test_loss_epoch_list, test_acc_epoch_list) in \
    enumerate(zip(activations, train_loss_list, test_loss_list, test_acc_list)):
    row, col = int(i/2), int(i%2)
    axs1[row, col].plot(train_loss_epoch_list, label='Train Loss', linewidth=0.8)
    axs1[row, col].plot(test_loss_epoch_list, label='Test Loss', linewidth=0.8)
    axs1[row, col].set_title(activation.upper())
    axs1[row, col].legend()
    axs1[row, col].grid(linestyle='--', linewidth=0.5, alpha=0.6)

    axs2[row, col].plot(test_acc_epoch_list, label='Test Acc', linewidth=0.8)
    axs2[row, col].set_title(activation.upper())
    axs2[row, col].legend()
    axs2[row, col].grid(linestyle='--', linewidth=0.5, alpha=0.6)

for ax in axs1.flat:
    ax.set(xlabel='Epoch', ylabel='Loss')
for ax in axs2.flat:
    ax.set(xlabel='Epoch', ylabel='Accuracy')

plt.show()



**可以将Loss做成曲线按照不同集合进行对比**
```
![](https://pzzzzzzzzz.github.io/images/2fb3359c66e0fb8b2b57f630fcb5b1a.png.png)
![](https://pzzzzzzzzz.github.io/images/ff91d5e0d0510025bd6b27dff9ceb52.png.png)