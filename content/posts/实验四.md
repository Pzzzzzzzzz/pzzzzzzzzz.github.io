---
title: "实验四"
date: 2023-05-2T13:46:02+08:00
draft: false
---

实验四：
目的：学习循环神经网络。
数据：心跳信号数据集（自己挑出1000条数据，设计训练集和测试集）；
实验内容：
1. 利用心跳信号数据集的分类，设计一个循环神经网络；
2. 比较普通循环网络和LSTM的区别；
3. 分析循环网络可能出现的问题，及问题发生的原因，以及LSTM是否能解决问题。



```python
import csv

# 打开原始csv文件
with open('心跳用于循环神经网络\\new.csv', mode='r') as csv_file:
    csv_reader = csv.DictReader(csv_file)

    # 创建并打开新csv文件，设置表头
    with open('新文件.csv', mode='w', newline='') as new_file:
        fieldnames = ['id',  'signal_1', 'signal_2', 'signal_3', 'signal_4', 'signal_5','label']
        csv_writer = csv.DictWriter(new_file, fieldnames=fieldnames)

        # 写入表头
        csv_writer.writeheader()

        # 遍历原始csv文件每一行数据
        for row in csv_reader:
            # 获取每行的信息
            id_val = row['id']
            label_val = row['label']
            signals = row['heartbeat_signals'].split(',')[:5]

            # 创建新行并写入新csv文件
            new_row = {
                'id': id_val,
                'label': label_val,
                'signal_1': signals[0],
                'signal_2': signals[1],
                'signal_3': signals[2],
                'signal_4': signals[3],
                'signal_5': signals[4]
            }
            csv_writer.writerow(new_row)

import pandas as pd
# 读取csv文件
data = pd.read_csv("心跳用于循环神经网络\新文件.csv")

# 删除第一列id列
data = data.drop(columns=["id"])

# 保存更改后的数据
data.to_csv("heart_sign.csv", index=False)

```

```python

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt


class HeartbeatDataset(Dataset):
    def __init__(self, data_file):
        # 读取数据文件
        self.data = torch.from_numpy(np.loadtxt(data_file, delimiter=',', dtype=np.float32,skiprows=1))
        
        # 将数据集分为输入序列和标签
        self.X = self.data[:, :-1]  # 输入序列
        self.y = self.data[:, -1]   # 标签
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, index):
        return self.X[index], self.y[index]

class RNNModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(RNNModel, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        batch_size = x.size(0)
        hidden = torch.zeros(1, batch_size, self.hidden_size).to(x.device)
        out, hidden = self.rnn(x, hidden)
        out = self.fc(hidden.squeeze(0))
        return out

class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        batch_size = x.size(0)
        hidden = torch.zeros(1, batch_size, self.hidden_size).to(x.device)
        cell = torch.zeros(1, batch_size, self.hidden_size).to(x.device)
        out, (hidden, cell) = self.lstm(x, (hidden, cell))
        out = self.fc(hidden.squeeze(0))
        return out

# 训练参数
num_epochs = 50
batch_size = 32
learning_rate = 0.001

# 加载数据集
dataset = HeartbeatDataset('心跳用于循环神经网络\heart_sign.csv')
train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# 定义模型、损失函数和优化器
input_size = dataset.X.shape[1]
output_size = len(torch.unique(dataset.y))
hidden_size = 128
rnn_model = RNNModel(input_size, hidden_size, output_size)
lstm_model = LSTMModel(input_size, hidden_size, output_size)
criterion = nn.CrossEntropyLoss()
rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)
lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)


train_rnn_losses = []
train_lstm_losses = []


# 训练模型
for epoch in range(num_epochs):
    total_rnn_loss = 0
    total_lstm_loss = 0
    for batch_x, batch_y in train_loader:
        # 计算 RNN 模型的损失
        rnn_optimizer.zero_grad()
        rnn_output = rnn_model(batch_x.unsqueeze(1))
        batch_y = batch_y.long()
        rnn_loss = criterion(rnn_output, batch_y)
        rnn_loss.backward()
        rnn_optimizer.step()
        total_rnn_loss += rnn_loss.item()

        # 计算 LSTM 模型的损失
        lstm_optimizer.zero_grad()
        lstm_output = lstm_model(batch_x.unsqueeze(1))
        lstm_loss = criterion(lstm_output, batch_y)
        lstm_loss.backward()
        lstm_optimizer.step()
        total_lstm_loss += lstm_loss.item()


    # 记录训练损失
    train_rnn_losses.append(total_rnn_loss / len(train_loader))
    train_lstm_losses.append(total_lstm_loss / len(train_loader))

    # 打印训练损失
    print(f'Epoch [{epoch + 1}/{num_epochs}], RNN loss: {total_rnn_loss / len(train_loader):.4f}, LSTM loss: {total_lstm_loss / len(train_loader):.4f}')
  
# 测试模型
with torch.no_grad():
    rnn_model.eval()
    lstm_model.eval()
    test_x = dataset.X.unsqueeze(1)
    test_y = dataset.y
    rnn_pred = rnn_model(test_x).argmax(1)
    lstm_pred = lstm_model(test_x).argmax(1)
    print(f'RNN accuracy: {(rnn_pred == test_y).sum().item() / len(test_y)}')
    print(f'LSTM accuracy: {(lstm_pred == test_y).sum().item() / len(test_y)}')

# 绘制损失函数随时间的变化图
plt.plot(range(num_epochs), train_rnn_losses, label='RNN')
plt.plot(range(num_epochs), train_lstm_losses, label='LSTM')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

```

![](https://pzzzzzzzzz.github.io/实验四/011912ba131c291e4d92e5e8ff81854.png)
普通的循环神经网络由于其可重复的连接方式和非线性激活函数，导致在训练时容易遇到梯度爆炸或消失问题。梯度爆炸会导致权重值失去平衡，从而影响学习结果；而梯度消失则表示网络无法有效地学习长期依赖性关系，并导致网络输出变得平稳。这些问题可以被通过使用更稳定的初始化方式、正则化和截断反向传播等技术来解决，但这些方法往往不够理想，而且不同的网络结构和不同的数据集需要不同的方法。

LSTM 网络是一种针对普通循环神经网络问题所提出的解决方案。LSTM 网络通过引入门控机制和细胞状态，克服了普通 RNN 的问题。门控机制允许网络在每个时间步骤选择性地输出信息，从而使网络更加高效和稳定。细胞状态允许网络有效地捕捉长期依赖性关系，使网络能够记住以前输入的信息，从而更好地预测后续的输出。

也就是说，LSTM 网络具有更好的性能和稳定性，能够更好地处理长序列和时间序列数据。而普通的循环神经网络在处理相对较短的数据时，例如一段文本或一段时间内的感知数据等，相比LSTM并不会出现显著的问题。