---
title: "不同卷积核大小，步长以及是否补零的影响基于MNIST"
date: 2023-04-08T13:46:02+08:00
draft: false
---

深度学习：第二个实验

目的：学习不同的卷积核（3，3）、（5，5）、（7，7）

数据：手写体数据；

实验内容：

1. 利用手写体数据的分类，设计一个卷积神经网络；

2. 利用（3，3）、（5，5）、（7，7）三种不同的卷积核、步长1、2，比较补零和不补零的结果。（要求设计2-3卷积层）

3. 利用公式，写出每层的输入和输出维度，并讨论维度的不同对于运行精确度和速度的影响。


```python

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt


# 定义超参数
input_size = 28 * 28
num_classes = 10
num_epochs = 10
batch_size = 100
learning_rate = 0.001

# MNIST数据集
train_dataset = dsets.MNIST(root='./data', 
                            train=True, 
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data', 
                           train=False, 
                           transform=transforms.ToTensor())

# 数据加载器
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)


class ConvNet(nn.Module):
    def __init__(self, num_classes):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*32, num_classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
     

# 不同的卷积核大小和padding的组合
kernel_sizes = [(3,3), (5,5), (7,7)]
paddings = [(0,0), (1,1)]
strides = [1, 2]

for kernel_size in kernel_sizes:
    for padding in paddings:
        for stride in strides:
            net = ConvNet(num_classes)
            criterion = nn.CrossEntropyLoss()
            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)


            # 定义存储loss和accury的列表
            train_loss_history = []
            train_acc_history = []
            test_loss_history = []
            test_acc_history = []


            # 训练模型
            total_step = len(train_loader)
            for epoch in range(num_epochs):
                for i, (images, labels) in enumerate(train_loader):
                    images = images.reshape(-1, 1, 28, 28)
                    # 前向传播
                    outputs = net(images)
                    loss = criterion(outputs, labels)

                    # 反向传播和优化
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    if (i+1) % 100 == 0:
                        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                               .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
                        

                    # 记录训练集的loss和accuracy
                    train_loss_history.append(loss.item())
                    _, predicted = torch.max(outputs.data, 1)
                    train_accuracy = torch.sum(predicted == labels.data).item() / len(labels)
                    train_acc_history.append(train_accuracy)

            # 测试模型
            with torch.no_grad():
                correct = 0
                total = 0
                for images, labels in test_loader:
                    images = images.reshape(-1, 1, 28, 28)
                    outputs = net(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                print('Kernel Size: {}, Padding: {}, Stride: {}, Test Accuracy: {:.2f}%'
                      .format(kernel_size, padding, stride, 100 * correct / total))

 # 可视化loss和accuracy
            plt.title('Loss for Kernel Size {}, Padding {}, Stride {}'.format(kernel_size, padding, stride))
            plt.plot(train_loss_history)
            plt.plot(test_loss_history)
            plt.legend(['train_loss', 'test_loss'])
            plt.show()

            plt.title('Accuracy for Kernel Size {}, Padding {}, Stride {}'.format(kernel_size, padding, stride))
            plt.plot(train_acc_history)
            plt.plot(test_acc_history)
            plt.legend(['train_acc', 'test_acc'])
            plt.show()

```

![](https://pzzzzzzzzz.github.io/images/loss1.png)
![](https://pzzzzzzzzz.github.io/images/acc1.png)

![](https://pzzzzzzzzz.github.io/images/loss2.png)
![](https://pzzzzzzzzz.github.io/images/acc2.png)

![](https://pzzzzzzzzz.github.io/images/loss3.png)
![](https://pzzzzzzzzz.github.io/images/acc3.png)

![](https://pzzzzzzzzz.github.io/images/loss4.png)
![](https://pzzzzzzzzz.github.io/images/acc4.png)

![](https://pzzzzzzzzz.github.io/images/loss5.png)
![](https://pzzzzzzzzz.github.io/images/acc5.png)

![](https://pzzzzzzzzz.github.io/images/loss6.png)
![](https://pzzzzzzzzz.github.io/images/acc6.png)

![](https://pzzzzzzzzz.github.io/images/loss7.png)
![](https://pzzzzzzzzz.github.io/images/acc7.png)

![](https://pzzzzzzzzz.github.io/images/loss8.png)
![](https://pzzzzzzzzz.github.io/images/acc8.png)

![](https://pzzzzzzzzz.github.io/images/loss9.png)
![](https://pzzzzzzzzz.github.io/images/acc9.png)

![](https://pzzzzzzzzz.github.io/images/loss10.png)
![](https://pzzzzzzzzz.github.io/images/acc10.png)

![](https://pzzzzzzzzz.github.io/images/loss11.png)
![](https://pzzzzzzzzz.github.io/images/acc11.png)

![](https://pzzzzzzzzz.github.io/images/loss12.png)
![](https://pzzzzzzzzz.github.io/images/acc12.png)

