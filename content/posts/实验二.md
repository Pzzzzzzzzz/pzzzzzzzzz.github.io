---
title: "不同卷积核大小，步长以及是否补零的影响基于MNIST"
date: 2023-04-08T13:46:02+08:00
draft: false
---

深度学习：第二个实验

目的：学习不同的卷积核（3，3）、（5，5）、（7，7）

数据：手写体数据；

实验内容：

1. 利用手写体数据的分类，设计一个卷积神经网络；

2. 利用（3，3）、（5，5）、（7，7）三种不同的卷积核、步长1、2，比较补零和不补零的结果。（要求设计2-3卷积层）

3. 利用公式，写出每层的输入和输出维度，并讨论维度的不同对于运行精确度和速度的影响。


```python

import torch
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt


# 定义超参数
input_size = 28 * 28
num_classes = 10
num_epochs = 10
batch_size = 100
learning_rate = 0.001

# MNIST数据集
train_dataset = dsets.MNIST(root='./data', 
                            train=True, 
                            transform=transforms.ToTensor(),
                            download=True)

test_dataset = dsets.MNIST(root='./data', 
                           train=False, 
                           transform=transforms.ToTensor())

# 数据加载器
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, 
                                           batch_size=batch_size, 
                                           shuffle=True)

test_loader = torch.utils.data.DataLoader(dataset=test_dataset, 
                                          batch_size=batch_size, 
                                          shuffle=False)


class ConvNet(nn.Module):
    def __init__(self, num_classes):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7*7*32, num_classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
     

# 不同的卷积核大小和padding的组合
kernel_sizes = [(3,3), (5,5), (7,7)]
paddings = [(0,0), (1,1)]
strides = [1, 2]

for kernel_size in kernel_sizes:
    for padding in paddings:
        for stride in strides:
            net = ConvNet(num_classes)
            criterion = nn.CrossEntropyLoss()
            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)


            # 定义存储loss和accury的列表
            train_loss_history = []
            train_acc_history = []
            test_loss_history = []
            test_acc_history = []


            # 训练模型
            total_step = len(train_loader)
            for epoch in range(num_epochs):
                for i, (images, labels) in enumerate(train_loader):
                    images = images.reshape(-1, 1, 28, 28)
                    # 前向传播
                    outputs = net(images)
                    loss = criterion(outputs, labels)

                    # 反向传播和优化
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    if (i+1) % 100 == 0:
                        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                               .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
                        

                    # 记录训练集的loss和accuracy
                    train_loss_history.append(loss.item())
                    _, predicted = torch.max(outputs.data, 1)
                    train_accuracy = torch.sum(predicted == labels.data).item() / len(labels)
                    train_acc_history.append(train_accuracy)

            # 测试模型
            with torch.no_grad():
                correct = 0
                total = 0
                for images, labels in test_loader:
                    images = images.reshape(-1, 1, 28, 28)
                    outputs = net(images)
                    _, predicted = torch.max(outputs.data, 1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()

                print('Kernel Size: {}, Padding: {}, Stride: {}, Test Accuracy: {:.2f}%'
                      .format(kernel_size, padding, stride, 100 * correct / total))

 # 可视化loss和accuracy
            plt.title('Loss for Kernel Size {}, Padding {}, Stride {}'.format(kernel_size, padding, stride))
            plt.plot(train_loss_history)
            plt.plot(test_loss_history)
            plt.legend(['train_loss', 'test_loss'])
            plt.show()

            plt.title('Accuracy for Kernel Size {}, Padding {}, Stride {}'.format(kernel_size, padding, stride))
            plt.plot(train_acc_history)
            plt.plot(test_acc_history)
            plt.legend(['train_acc', 'test_acc'])
            plt.show()

```

![](https://pzzzzzzzzz.github.io/实验二images/loss1.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc1.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss2.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc2.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss3.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc3.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss4.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc4.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss5.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc5.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss6.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc6.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss7.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc7.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss8.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc8.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss9.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc9.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss10.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc10.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss11.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc11.png)

![](https://pzzzzzzzzz.github.io/实验二images/loss12.png)
![](https://pzzzzzzzzz.github.io/实验二images/acc12.png)


首先是输入层，该网络采用MNIST手写数字图片作为输入，每张图片大小为28 x28 x1 (一个通道)
然后是第一层卷积层，该层的输入维度为28 x28 x 1，卷积核大小为(3,3) ，步长为1，padding为 (1,1) ，卷积核的个数为32，输出维度为28 x 28 x32。代码中，使用了三种卷积核大小(3 x 3，5 x 5，7 x 7) ，以及两种padding方式 ( (0,0)， (1,1) ) ，可以看到在不同的卷积核大小、步长和padding方式下，输出维度不同。在同一大小的卷积核下，使用padding方式为 (1,1) 时，输出维度相对较大，这是因为通过padding在图像边缘添加了一圈像素，使得原本不足以卷积的像素能够被卷积。可以看到对于同一卷积核大小,使用不同的padding情况下，输出维度不同。同时，在使用更大的卷积核 (例如7 x 7时)，输出的维度相对更小，这是因为卷积核在沿着H和W方向上进行滑动时的步长更大，导致输出维度的变化。

在代码中，我们使用了与第一层卷积层相同的卷积核大小、Padding和步长，因此第二层卷积层输出的维度与第一层卷积层输入的维度相差无几。维度的不同对于运行精确度和速度的影响与第一层卷积层类似。

在代码中，我们将第三层全连接层的输入维度设置为7 x 7 x 32，并将输出维度设置为10。全连接层主要是通过将卷积层的输出视为一个向量，因此其维度变化相对较小。

总结：当网络的输入和中间层的维度变大时，模型需要处理更多的数据，计算量也会随之增加，导致运行速度变慢。但是，在每个网络层选择的卷积核尺寸、步长、padding 等不同参数的设置，也会对模型的速度和精确度产生影响。

例如，在卷积层中，卷积核和padding的设置都会影响输出的维度和计算速度。使用较大的卷积核和更多的卷积核在提取图像特征方面更有效，但是卷积核的增加也相应地增加了计算复杂度，会使模型训练和测试的时间变慢。相反，使用较小的卷积核和更少的卷积核可以在一定程度上减少计算量，提高运行速度，但是可能会失去某些图像特征的细节，影响建模精度。因此在实际应用中需要根据数据集的影响因素及识别的需求选择合理的卷积核大小。

池化操作在空间上缩小特征图的大小，并进一步减少了计算量。

最后，全连接层会带来大量的模型参数，从而占用大量的内存，增加运行时间。